# Background

The Capstone project is the cornerstone project that is the crux of the Data Science Immersive program at General Assembly. I have decided to do my project with a dataset that analyzes a dataset that consists of population demographic and socioeconomic data of census tracts in the United States. It also has a feature that designates whether the census tract has a Superfund site or not with 1 designating a Superfund site that exists and 0 designating a Superfund site that does not exist. My problem statement was to look at what are the most important features that predict a census tract will have a Superfund site. Could it be lower income households? Could it be minorities? Could it be lower educated individuals? In order to do this, I will utilize decision trees to model my data. I created a variety of ensemble methods that include a Random Forest Classifier, Adaboost Classifier, Gradient Boosting Classifier, a Logistic Regression, and an Extreme Gradient Boosting Classifier. After selecting my best model, I will know what are the most important features that are associated with a census tract that has a Superfund site.

# Data

The data was downloaded from Kaggle.com that consists of over 70,000 census tracts from 50 states and Puerto Rico. The features range from population demographics, income, housing values, age groups, employment, etc. This dataset has over 500 features for me to choose from to put into a model. I had features that looked at how many people spoke a specific language or if they spoke it very well, whether they had plumbing or not, or whether they lived in a mobile home or not. I decided not to include these kind of features. Also I had data that was collected from the Census Bureau and the American Community Survey. I decided to go with features that was collected by the Census Bureau. There are features in the dataset that haven't been collected by the Census Bureau not by the American Community Survey. I decided to include those features as well. My response variable is very unbalanced, so I conducted oversampling, undersampling and weighting my observations to account for this and evaluate my models on the original data.

# Project Timeline

This project has allowed me to put into practice the data science workflow such as data cleaning/munging, EDA, feature engineering, and model building. Since I have a lot of features to deal with so I conducted massive feature elimination to drop a lot of features that I see as unnecessary to incorporate into my model. I also conducted data cleaning/munging in order to clean up my features that had symbols, commas, and whitespaces. Then I conducted some extensive EDA of my data to detect patterns, behavior and relationships among my data. I actually decided to conduct some preliminary modeling (without hyperparameter tuning) after dropping null values. I realized that I have at most 5% null values, I decided that it won't have an impact on my modeling. I pondered using a model to impute missing values or using other imputations, but decided not to mainly on time constraints.

I realized that after my preliminary modeling, I needed to add new features and featuers that I dropped earlier were actually pretty important. Therefore, I went back to my original dataset and included features that seemed to capture attributes such as population, employment, and income. I also created features such as number employed, number unemployed, employed:unemployed ratio, and interaction terms between income and ethnicity. 

I created a multitude of classification models to look into what features are the most predicted of a census tract that have a Superfund site. After running through the models, I consistently was not able to get a single performing model. My features could not distinguish between census tracts that had a Superfund site from those that do not. 

# Conclusion

Therefore, the data analysis is inconclusive as I cannot come to a conclusion after analyzing the data what the important features are of census tracts with a Superfund site. There needs to be more data collected and a dataset that can be able to distinguish between communities with and without a Superfund site. 
